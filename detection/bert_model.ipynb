{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('env_cpb': conda)",
      "metadata": {
        "interpreter": {
          "hash": "6e562eb495edbd98b4705d13b4dc4f4058fca01d43484b094130bc2fb66d6fcd"
        }
      }
    },
    "colab": {
      "name": "bert_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6B_gq2KP8hy",
        "outputId": "402afe11-ff1c-4137-cb2a-928791b6f760"
      },
      "source": [
        "!pip install transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "\n",
        "from torch import cuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "_l4fmkEsP8h4",
        "outputId": "e3d33a6d-424d-44e3-d75b-9aa6062f8432"
      },
      "source": [
        "device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"data.csv\", index_col=False)\n",
        "df_copy = df[[\"text\", \"super_strategy_label\"]].copy()\n",
        "df_copy.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>super_strategy_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The PressTV references in Wikipedia's \"Turkey-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you have time, can you correct the titles?</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had really hoped to get some more opinions o...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I modified it a bit, possibly vote to reopen?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Well the only plausible explanation was that y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  super_strategy_label\n",
              "0  The PressTV references in Wikipedia's \"Turkey-...                     1\n",
              "1      If you have time, can you correct the titles?                     3\n",
              "2  I had really hoped to get some more opinions o...                     6\n",
              "3      I modified it a bit, possibly vote to reopen?                     4\n",
              "4  Well the only plausible explanation was that y...                     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LubvY9fVP8h5",
        "outputId": "b755baca-bcf6-42a8-bfb2-c0ef30637ae9"
      },
      "source": [
        "# Clean the text \n",
        "def normalise_text(text):\n",
        "    text = text.strip()\n",
        "    text = text.lower() # lowercase\n",
        "    text = text.replace(r\"\\#\",\"\") # replaces hashtags\n",
        "    text = text.replace(r\"http\\S+\",\"URL\")  # remove URL addresses\n",
        "    text = text.replace(r\"@\",\"\")\n",
        "    text = text.replace(r\"[^A-Za-z0-9()!?\\'\\`\\\"]\", \" \")\n",
        "    text = text.replace(\"\\s{2,}\", \" \")\n",
        "    text = text.replace(r\"\\#\",\"\")\n",
        "    return text\n",
        "df_copy.text = df_copy.text.apply(normalise_text)\n",
        "df_copy.columns = [\"text\", \"label\"]\n",
        "df_copy.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5094 entries, 0 to 5093\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    5094 non-null   object\n",
            " 1   label   5094 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 79.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F8JOUmaP8h5",
        "outputId": "166d60a5-e280-4468-91be-f23c25454000"
      },
      "source": [
        "# keep 1/4 0 label\n",
        "df_1 = df_copy.loc[df_copy.label > 0] \n",
        "df_0 = df_copy.loc[df_copy.label == 0]\n",
        "df_0 = df_0.reset_index()\n",
        "df_0 = df_0.sample(frac=0.25, replace=True, random_state=1)\n",
        "train_df = pd.concat([df_1, df_0], ignore_index=True)\n",
        "train_df = train_df.sample(frac=1)\n",
        "train_df = train_df[[\"text\", \"label\"]]\n",
        "train_df.to_csv(\"clean_dataset.csv\", index=False)\n",
        "print(train_df)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   text  label\n",
            "243                                   please see <url>.      3\n",
            "3135  you have listed it as no source but the author...      0\n",
            "800   and since you are a well trusted user i am ask...      4\n",
            "3305  that was a nice pic you put up in the civil wa...      0\n",
            "1707  it's not explicit, but it seems like you want ...      4\n",
            "...                                                 ...    ...\n",
            "3258                              this sounds familiar.      0\n",
            "1018  thank you for getting to all those wikiproject...      7\n",
            "2467  have you tried asking on the distutils-sig mai...      4\n",
            "2074  isn't it better to use the appropriate `select...      1\n",
            "3290           does view source give you the same code?      0\n",
            "\n",
            "[3562 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERTkcGF2P8h6",
        "outputId": "7b769548-8e5e-438d-ea26-1ce56f1d0d9a"
      },
      "source": [
        "# find max length\n",
        "def get_text_len(text):\n",
        "    return len(text.split(\" \"))\n",
        "max_len = max(train_df.text.apply(get_text_len))\n",
        "max_len"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BN1zPyVP8h6"
      },
      "source": [
        "MAX_LEN = 100\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 1e-05\n",
        "CLASS_SIZE = 8\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hYQPZVXP8h7"
      },
      "source": [
        "class PDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.data.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.data.label[index], dtype=torch.long)\n",
        "        } \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2sTGd9AP8h7",
        "outputId": "c09b98c7-81e2-4ae0-a7c1-1366e964a88b"
      },
      "source": [
        "train_size = 0.8\n",
        "train_dataset = train_df.sample(frac=train_size, random_state=200)\n",
        "test_dataset= train_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(train_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = PDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = PDataset(test_dataset, tokenizer, MAX_LEN)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: (3562, 2)\n",
            "TRAIN Dataset: (2850, 2)\n",
            "TEST Dataset: (712, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ed7lZm5P8h7"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjuBrlLEP8h8",
        "outputId": "b5c1c635-634e-4ab3-846a-640656f7e49b"
      },
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = BertModel.from_pretrained(\"bert-base-uncased\",return_dict=False)\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, CLASS_SIZE)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m55aVCAmP8h8"
      },
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJju8YnJP8h8"
      },
      "source": [
        "# Function to calcuate the accuracy of the model\n",
        "\n",
        "def calcuate_accu(big_idx, targets):\n",
        "    n_correct = (big_idx==targets).sum().item()\n",
        "    return n_correct"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WijjEnVPP8h9"
      },
      "source": [
        "def train(epoch):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(ids, mask)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        tr_loss += loss.item()\n",
        "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "        n_correct += calcuate_accu(big_idx, targets)\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples+=targets.size(0)\n",
        "        \n",
        "        if _ % 1000 == 0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            accu_step = (n_correct * 100)/nb_tr_examples \n",
        "            print(f\"Training Loss per 1000 steps: {loss_step}\")\n",
        "            print(f\"Training Accuracy per 1000 steps: {accu_step}%\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # # When using GPU\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct * 100)/nb_tr_examples}%')\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct * 100)/nb_tr_examples\n",
        "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy Epoch: {epoch_accu}%\")\n",
        "    print(\"===========================\")\n",
        "\n",
        "    return epoch_loss, epoch_accu\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY-F21cIP8h9",
        "outputId": "7ed1251f-7fe5-4e05-b31c-98f0accb1909"
      },
      "source": [
        "from pandas import DataFrame\n",
        "epochs_loss_history = []\n",
        "epochs_accu_history = []\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss, epoch_accu = train(epoch)\n",
        "    epochs_loss_history.append(epoch_loss)\n",
        "    epochs_accu_history.append(epoch_accu)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Loss per 1000 steps: 2.0276291370391846\n",
            "Training Accuracy per 1000 steps: 6.25%\n",
            "The Total Accuracy for Epoch 0: 49.1578947368421%\n",
            "Training Loss Epoch: 1.4548758348273165\n",
            "Training Accuracy Epoch: 49.1578947368421%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.9762874245643616\n",
            "Training Accuracy per 1000 steps: 68.75%\n",
            "The Total Accuracy for Epoch 1: 68.59649122807018%\n",
            "Training Loss Epoch: 0.9300150399268007\n",
            "Training Accuracy Epoch: 68.59649122807018%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 1.1390187740325928\n",
            "Training Accuracy per 1000 steps: 62.5%\n",
            "The Total Accuracy for Epoch 2: 78.94736842105263%\n",
            "Training Loss Epoch: 0.6562623730834636\n",
            "Training Accuracy Epoch: 78.94736842105263%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.706458568572998\n",
            "Training Accuracy per 1000 steps: 75.0%\n",
            "The Total Accuracy for Epoch 3: 88.28070175438596%\n",
            "Training Loss Epoch: 0.4322126451983798\n",
            "Training Accuracy Epoch: 88.28070175438596%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.6520106196403503\n",
            "Training Accuracy per 1000 steps: 68.75%\n",
            "The Total Accuracy for Epoch 4: 91.96491228070175%\n",
            "Training Loss Epoch: 0.28351887146937116\n",
            "Training Accuracy Epoch: 91.96491228070175%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.2790469527244568\n",
            "Training Accuracy per 1000 steps: 81.25%\n",
            "The Total Accuracy for Epoch 5: 95.47368421052632%\n",
            "Training Loss Epoch: 0.1785107154357533\n",
            "Training Accuracy Epoch: 95.47368421052632%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.026444552466273308\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 6: 97.71929824561404%\n",
            "Training Loss Epoch: 0.10819161208814748\n",
            "Training Accuracy Epoch: 97.71929824561404%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.03421403095126152\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 7: 98.87719298245614%\n",
            "Training Loss Epoch: 0.0682878688227531\n",
            "Training Accuracy Epoch: 98.87719298245614%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.01900864578783512\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 8: 99.33333333333333%\n",
            "Training Loss Epoch: 0.046839318347460066\n",
            "Training Accuracy Epoch: 99.33333333333333%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.03593642637133598\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 9: 99.47368421052632%\n",
            "Training Loss Epoch: 0.031575907344341944\n",
            "Training Accuracy Epoch: 99.47368421052632%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.018957462161779404\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 10: 99.26315789473684%\n",
            "Training Loss Epoch: 0.038775265471770445\n",
            "Training Accuracy Epoch: 99.26315789473684%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.1229628473520279\n",
            "Training Accuracy per 1000 steps: 93.75%\n",
            "The Total Accuracy for Epoch 11: 99.64912280701755%\n",
            "Training Loss Epoch: 0.022362742632856415\n",
            "Training Accuracy Epoch: 99.64912280701755%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.024118592962622643\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 12: 99.6842105263158%\n",
            "Training Loss Epoch: 0.017134572626429728\n",
            "Training Accuracy Epoch: 99.6842105263158%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.004078884143382311\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 13: 99.47368421052632%\n",
            "Training Loss Epoch: 0.021956302653529873\n",
            "Training Accuracy Epoch: 99.47368421052632%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0069558098912239075\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 14: 99.40350877192982%\n",
            "Training Loss Epoch: 0.02389857654105976\n",
            "Training Accuracy Epoch: 99.40350877192982%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.005391196813434362\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 15: 99.9298245614035%\n",
            "Training Loss Epoch: 0.008474649602609723\n",
            "Training Accuracy Epoch: 99.9298245614035%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.004432082176208496\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 16: 99.75438596491227%\n",
            "Training Loss Epoch: 0.013861030540507099\n",
            "Training Accuracy Epoch: 99.75438596491227%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.007181487511843443\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 17: 99.85964912280701%\n",
            "Training Loss Epoch: 0.009369828540561252\n",
            "Training Accuracy Epoch: 99.85964912280701%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0021143921185284853\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 18: 99.6842105263158%\n",
            "Training Loss Epoch: 0.013953600531475171\n",
            "Training Accuracy Epoch: 99.6842105263158%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0025006753858178854\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 19: 99.15789473684211%\n",
            "Training Loss Epoch: 0.02597296967785077\n",
            "Training Accuracy Epoch: 99.15789473684211%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.004922281019389629\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 20: 99.6140350877193%\n",
            "Training Loss Epoch: 0.01640261164879395\n",
            "Training Accuracy Epoch: 99.6140350877193%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.002448447747156024\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 21: 99.78947368421052%\n",
            "Training Loss Epoch: 0.0093838876294097\n",
            "Training Accuracy Epoch: 99.78947368421052%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.017033297568559647\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 22: 100.0%\n",
            "Training Loss Epoch: 0.0033750699308841337\n",
            "Training Accuracy Epoch: 100.0%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.002155279042199254\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 23: 99.96491228070175%\n",
            "Training Loss Epoch: 0.003304729903801006\n",
            "Training Accuracy Epoch: 99.96491228070175%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0011904140701517463\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 24: 99.96491228070175%\n",
            "Training Loss Epoch: 0.002606636256970694\n",
            "Training Accuracy Epoch: 99.96491228070175%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0026726610958576202\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 25: 99.89473684210526%\n",
            "Training Loss Epoch: 0.0066668204647780255\n",
            "Training Accuracy Epoch: 99.89473684210526%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.002821520436555147\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 26: 99.89473684210526%\n",
            "Training Loss Epoch: 0.00490987142622757\n",
            "Training Accuracy Epoch: 99.89473684210526%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0021182349883019924\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 27: 99.40350877192982%\n",
            "Training Loss Epoch: 0.021051142233041473\n",
            "Training Accuracy Epoch: 99.40350877192982%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.002930008340626955\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 28: 99.57894736842105%\n",
            "Training Loss Epoch: 0.015721969528243403\n",
            "Training Accuracy Epoch: 99.57894736842105%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0021751374006271362\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 29: 99.78947368421052%\n",
            "Training Loss Epoch: 0.006291287162278742\n",
            "Training Accuracy Epoch: 99.78947368421052%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0010174063500016928\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 30: 99.85964912280701%\n",
            "Training Loss Epoch: 0.004831926867901738\n",
            "Training Accuracy Epoch: 99.85964912280701%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.001898468122817576\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 31: 99.89473684210526%\n",
            "Training Loss Epoch: 0.004186558389389763\n",
            "Training Accuracy Epoch: 99.89473684210526%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0010329546639695764\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 32: 99.75438596491227%\n",
            "Training Loss Epoch: 0.009291961416146879\n",
            "Training Accuracy Epoch: 99.75438596491227%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0013454084983095527\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 33: 99.9298245614035%\n",
            "Training Loss Epoch: 0.004341545732472061\n",
            "Training Accuracy Epoch: 99.9298245614035%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.016058040782809258\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 34: 99.82456140350877%\n",
            "Training Loss Epoch: 0.011808816506787511\n",
            "Training Accuracy Epoch: 99.82456140350877%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.012874304316937923\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 35: 99.85964912280701%\n",
            "Training Loss Epoch: 0.005603613644576886\n",
            "Training Accuracy Epoch: 99.85964912280701%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0012723321560770273\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 36: 99.96491228070175%\n",
            "Training Loss Epoch: 0.0025418417930847563\n",
            "Training Accuracy Epoch: 99.96491228070175%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0005533384392037988\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 37: 99.9298245614035%\n",
            "Training Loss Epoch: 0.0021630273031151472\n",
            "Training Accuracy Epoch: 99.9298245614035%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0006205585086718202\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 38: 99.9298245614035%\n",
            "Training Loss Epoch: 0.0026168240380262716\n",
            "Training Accuracy Epoch: 99.9298245614035%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0004112187889404595\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 39: 100.0%\n",
            "Training Loss Epoch: 0.0007081059250406994\n",
            "Training Accuracy Epoch: 100.0%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.00041833860450424254\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 40: 100.0%\n",
            "Training Loss Epoch: 0.0011555527506152939\n",
            "Training Accuracy Epoch: 100.0%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0016966500552371144\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 41: 100.0%\n",
            "Training Loss Epoch: 0.0006523507709976535\n",
            "Training Accuracy Epoch: 100.0%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0006955695571377873\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 42: 99.78947368421052%\n",
            "Training Loss Epoch: 0.009046459811487282\n",
            "Training Accuracy Epoch: 99.78947368421052%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0014466543216258287\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 43: 99.57894736842105%\n",
            "Training Loss Epoch: 0.018659934645317698\n",
            "Training Accuracy Epoch: 99.57894736842105%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.14418169856071472\n",
            "Training Accuracy per 1000 steps: 93.75%\n",
            "The Total Accuracy for Epoch 44: 99.82456140350877%\n",
            "Training Loss Epoch: 0.008883392195706385\n",
            "Training Accuracy Epoch: 99.82456140350877%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.001247047446668148\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 45: 99.89473684210526%\n",
            "Training Loss Epoch: 0.002650458625987349\n",
            "Training Accuracy Epoch: 99.89473684210526%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.00045744821545667946\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 46: 100.0%\n",
            "Training Loss Epoch: 0.0007207843702834089\n",
            "Training Accuracy Epoch: 100.0%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0003471171366982162\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 47: 100.0%\n",
            "Training Loss Epoch: 0.00045915818475668097\n",
            "Training Accuracy Epoch: 100.0%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.0004315174010116607\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 48: 100.0%\n",
            "Training Loss Epoch: 0.00042387815621582655\n",
            "Training Accuracy Epoch: 100.0%\n",
            "===========================\n",
            "Training Loss per 1000 steps: 0.00044189239270053804\n",
            "Training Accuracy per 1000 steps: 100.0%\n",
            "The Total Accuracy for Epoch 49: 100.0%\n",
            "Training Loss Epoch: 0.00040212539385603587\n",
            "Training Accuracy Epoch: 100.0%\n",
            "===========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em33mbwY4Wlj"
      },
      "source": [
        "df = DataFrame(epochs_loss_history, columns=['bert_epochs_loss_history'])\n",
        "df[\"bert_epochs_accu_history\"] = epochs_accu_history\n",
        "df.to_csv(\"bert_history.csv\", index=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbd8HRhpP8h-"
      },
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "def valid(model, testing_loader):\n",
        "    model.eval()\n",
        "    tr_loss = 0\n",
        "    n_correct = 0 \n",
        "    n_wrong = 0\n",
        "    total = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    f1 = 0.0\n",
        "    targets_list = []\n",
        "    big_idx_list = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.long)\n",
        "            targets_list.extend(targets.tolist())\n",
        "            outputs = model(ids, mask).squeeze()\n",
        "            loss = loss_function(outputs, targets)\n",
        "            tr_loss += loss.item()\n",
        "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "            big_idx_list.extend(big_idx.tolist())\n",
        "            n_correct += calcuate_accu(big_idx, targets)\n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples+=targets.size(0)\n",
        "            \n",
        "            if _%100 == 0:\n",
        "                loss_step = tr_loss/nb_tr_steps\n",
        "                accu_step = (n_correct * 100)/nb_tr_examples\n",
        "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
        "                print(f\"Validation Accuracy per 100 steps: {accu_step}%\")\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct * 100)/nb_tr_examples\n",
        "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Validation Accuracy Epoch: {epoch_accu}%\")\n",
        "    f1 = f1_score(targets_list, big_idx_list, average='macro')\n",
        "    confusion_mat = confusion_matrix(targets_list, big_idx_list, normalize='all')\n",
        "\n",
        "    return epoch_accu, f1, confusion_mat\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QIFNl1kNP8h-",
        "outputId": "acf7ee8d-30dd-470a-d192-596f65c2f955"
      },
      "source": [
        "acc, f1, confusion_mat = valid(model, testing_loader)\n",
        "print(f\"Accuracy on test data: {acc}\")\n",
        "print(f\"Marco F1 score: {f1}\")\n",
        "print(\"Confusion Matrix: \", confusion_mat)\n",
        "\n",
        "!pip install seaborn\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_mat, index = [i for i in \"01234567\"],\n",
        "                  columns = [i for i in \"01234567\"])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('bert_712_confusion_matrix.png', dpi=400)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Loss per 100 steps: 0.00020265279454179108\n",
            "Validation Accuracy per 100 steps: 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss Epoch: 1.0163302041808984\n",
            "Validation Accuracy Epoch: 84.8314606741573%\n",
            "Accuracy on test data: 84.8314606741573\n",
            "Marco F1 score: 0.7192671387347549\n",
            "Confusion Matrix:  [[0.11235955 0.03370787 0.         0.00702247 0.00561798 0.\n",
            "  0.         0.        ]\n",
            " [0.02808989 0.0997191  0.         0.00140449 0.00983146 0.00140449\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.00140449 0.        ]\n",
            " [0.00421348 0.00140449 0.         0.21910112 0.01123596 0.\n",
            "  0.00140449 0.        ]\n",
            " [0.00702247 0.00702247 0.         0.00983146 0.28792135 0.\n",
            "  0.00140449 0.        ]\n",
            " [0.         0.         0.         0.00140449 0.00280899 0.00561798\n",
            "  0.         0.        ]\n",
            " [0.00140449 0.00421348 0.         0.00280899 0.00561798 0.\n",
            "  0.05758427 0.        ]\n",
            " [0.         0.         0.         0.         0.00140449 0.\n",
            "  0.         0.06601124]]\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.11.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2ARhVseP8h-",
        "outputId": "be2f1bd5-85d1-427d-94b6-4a719c4e3d02"
      },
      "source": [
        "output_model_file = 'pytorch_bert_model.bin'\n",
        "output_vocab_file = 'vocab_bert_model.bin'\n",
        "\n",
        "model_to_save = model\n",
        "torch.save(model_to_save, output_model_file)\n",
        "tokenizer.save_vocabulary(output_vocab_file)\n",
        "\n",
        "print('All files saved')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All files saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "CdaDUkG8P8h-",
        "outputId": "780b792c-23f9-481a-ba42-4cecce272218"
      },
      "source": [
        "# human annotated testset\n",
        "df = pd.read_csv(\"testset_human.csv\", index_col=False)\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>if you have time, can you correct the titles?</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i had really hoped to get some more opinions o...</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i modified it a bit, possibly vote to reopen?</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>well the only plausible explanation was that y...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is that what indeed occurred?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0      if you have time, can you correct the titles?    3.0\n",
              "1  i had really hoped to get some more opinions o...    6.0\n",
              "2      i modified it a bit, possibly vote to reopen?    6.0\n",
              "3  well the only plausible explanation was that y...    1.0\n",
              "4                      is that what indeed occurred?    1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byWKro2-A53x"
      },
      "source": [
        "testing_set = PDataset(df, tokenizer, MAX_LEN)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "HXiVXNm7BGvM",
        "outputId": "45d35e60-075f-4f62-e2ed-c9c03025c437"
      },
      "source": [
        "acc, f1, confusion_mat = valid(model, testing_loader)\n",
        "print(f\"Accuracy on test data: {acc}\")\n",
        "print(f\"Marco F1 score: {f1}\")\n",
        "print(\"Confusion Matrix: \", confusion_mat)\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_mat, index = [i for i in \"01234567\"],\n",
        "                  columns = [i for i in \"01234567\"])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('bert_50_confusion_matrix.png', dpi=400)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Loss per 100 steps: 0.0007925463723950088\n",
            "Validation Accuracy per 100 steps: 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss Epoch: 4.093509748336926\n",
            "Validation Accuracy Epoch: 53.84615384615385%\n",
            "Accuracy on test data: 53.84615384615385\n",
            "Marco F1 score: 0.5146995161701045\n",
            "Confusion Matrix:  [[0.13461538 0.07692308 0.         0.         0.01923077 0.01923077\n",
            "  0.         0.        ]\n",
            " [0.01923077 0.07692308 0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.03846154 0.01923077 0.03846154 0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.11538462 0.03846154 0.\n",
            "  0.         0.        ]\n",
            " [0.         0.05769231 0.         0.03846154 0.09615385 0.01923077\n",
            "  0.03846154 0.        ]\n",
            " [0.01923077 0.01923077 0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.03846154 0.\n",
            "  0.01923077 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.05769231]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn-NUXyVBKFV"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}