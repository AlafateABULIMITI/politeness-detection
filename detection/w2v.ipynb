{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('env_cpb': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6e562eb495edbd98b4705d13b4dc4f4058fca01d43484b094130bc2fb66d6fcd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pp\n",
    "from rich import print\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1_gram(docs, save_path, size=300, window=5, min_count=1, epochs=100):\n",
    "    \"\"\"\"build the word2vec model according to the data\n",
    "    Arguments:\n",
    "        docs {list} -- documents with the form of list\n",
    "        path {str} -- the path where we want to save the model.\n",
    "    Keyword Arguments:\n",
    "        size {int} --  Dimensionality of the word vectors. (default: {200})\n",
    "        window {int} --The maximum distance between the current and predicted word within a sentence. (default: {3})\n",
    "        min_count {int} -- The model ignores all words with total frequency lower than this (default: {1})\n",
    "        epochs {int} -- Number of iterations (epochs) over the corpus. (default: {100})\n",
    "    Returns:\n",
    "        [model] -- the word2vec model\n",
    "    \"\"\"\n",
    "    model = Word2Vec(size=size, window=window, min_count=min_count, workers=300)\n",
    "    model.build_vocab(sentences=docs)\n",
    "    model.train(sentences=docs, total_examples=len(docs), epochs=epochs)\n",
    "    model.save(save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<rich.jupyter.JupyterRenderable at 0x7fb28200cb50>",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n    <span style=\"color: #008000\">'The PressTV references in Wikipedia\\'s \"Turkey-PKK Conflict\" article are not the same, </span>\n<span style=\"color: #008000\">but the titles are wrong.  If you have time, can you correct the titles?'</span>,\n    <span style=\"color: #008000\">'I had really hoped to get some more opinions on this question. I modified it a bit, </span>\n<span style=\"color: #008000\">possibly vote to reopen?'</span>,\n    <span style=\"color: #008000\">\"Well the only plausible explanation was that you reverted to where I removed an </span>\n<span style=\"color: #008000\">extraneous cat (after Homestarmy's edit) and then swapped out a template... but as you're a </span>\n<span style=\"color: #008000\">competent editor that just seemed odd. Is that what indeed occurred?\"</span>,\n    <span style=\"color: #008000\">\"I didn't quite understand, what are you trying to achieve? What questions do you have </span>\n<span style=\"color: #008000\">and what is the desired output?\"</span>,\n    <span style=\"color: #008000\">\"Hi, I'd like to help you with the image you just uploaded to the &lt;url&gt; article.  Can you</span>\n<span style=\"color: #008000\">tell me where you found it?\"</span>,\n    <span style=\"color: #008000\">'Yes, that is the real source code. And the compilation has been performed without </span>\n<span style=\"color: #008000\">optimization, perhaps that is the reason?'</span>,\n    <span style=\"color: #008000\">'In that case it might not be the answer then (hence the comment). Are you using the VS </span>\n<span style=\"color: #008000\">web server or IIS Express?'</span>,\n    <span style=\"color: #008000\">\"Thanks Cameron.  That makes sense, but then why isn't this access restricted to only </span>\n<span style=\"color: #008000\">copy constructors and assignment operators?\"</span>,\n    <span style=\"color: #008000\">'\"pyparsing\" appears to be a word specific to Python.  Is there a more general </span>\n<span style=\"color: #008000\">programming term for that type of action?'</span>,\n    <span style=\"color: #008000\">'The solution reported in the issue report is to replace any occurrence of </span>\n<span style=\"color: #008000\">`unset($form[$id])` with `$form[$id] = array(\\'#language\\' =&gt; NULL)` in the module file; it </span>\n<span style=\"color: #008000\">just a matter of doing a \"search and replace\" on a file. What do you exactly don\\'t </span>\n<span style=\"color: #008000\">understand?'</span>\n<span style=\"font-weight: bold\">]</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/should_be_annotated.csv\")\n",
    "l = pp.sents_2_list(df)\n",
    "print(l[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7fb282147bb0>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "build_1_gram(l[:10],\"../model/test_w2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-96ba18d79b00>, line 6)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-96ba18d79b00>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print(max_sent)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stack_df = pd.read_csv(\"../data/stack.csv\")\n",
    "texts = stack_df.text.values\n",
    "\n",
    "max_sent = max(text, key=len).split(\" \")\n",
    "max_len = max(map(list(map(texts, lambda x: x.split(\" \")),len))\n",
    "print(max_sent)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3f9c52c763f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "texts = stack_df.text.values\n",
    "l = list(map(texts, lambda x: x.split()))[1:3]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}